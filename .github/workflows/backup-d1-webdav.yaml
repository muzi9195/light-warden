name: Backup D1 Database to WebDAV

on:
  schedule:
    - cron: "0 4 * * *"  # UTC 04:00
  workflow_dispatch:
    inputs:
      environment:
        description: "Select the environment to backup"
        required: true
        default: "production"
        type: choice
        options:
          - production
          - dev

env:
  BACKUP_RETENTION_DAYS: 30

jobs:
  backup-production:
    name: Backup Production D1 ‚Üí WebDAV
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.environment == 'production'

    steps:
      - name: Checkout (optional, just to have a workspace)
        uses: actions/checkout@v4

      - name: Get current date
        id: date
        run: echo "date=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT

      - name: Install wrangler
        run: npm install -g wrangler

      - name: Get D1 Database Name
        id: db_name
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          DB_NAME=$(npx wrangler d1 list --json | jq -r '.[] | select(.uuid == "${{ secrets.D1_DATABASE_ID }}") | .name')
          if [ -z "$DB_NAME" ]; then
            echo "‚ùå Error: Could not find database with D1_DATABASE_ID"
            exit 1
          fi
          echo "db_name=$DB_NAME" >> $GITHUB_OUTPUT

      - name: Export & Compress D1 Database
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          npx wrangler d1 export "${{ steps.db_name.outputs.db_name }}" --remote --output=backup.sql
          gzip backup.sql

      - name: Encrypt backup (optional)
        id: encrypt
        env:
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
        run: |
          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 \
              -in backup.sql.gz \
              -out "vault1_prod_${{ steps.date.outputs.date }}.sql.gz.enc" \
              -pass pass:"$BACKUP_ENCRYPTION_KEY"
            echo "encrypted=true" >> $GITHUB_OUTPUT
            echo "filename=vault1_prod_${{ steps.date.outputs.date }}.sql.gz.enc" >> $GITHUB_OUTPUT
            rm backup.sql.gz
          else
            mv backup.sql.gz "vault1_prod_${{ steps.date.outputs.date }}.sql.gz"
            echo "encrypted=false" >> $GITHUB_OUTPUT
            echo "filename=vault1_prod_${{ steps.date.outputs.date }}.sql.gz" >> $GITHUB_OUTPUT
          fi
      - name: Test WebDAV with curl
        env:
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASS: ${{ secrets.WEBDAV_PASS }}
        run: |
          echo "üîç Testing WebDAV access with curl..."
          # PROPFIND request to check if auth works
          curl -u "$WEBDAV_USER:$WEBDAV_PASS" \
               -X PROPFIND \
               -H "Content-Type: application/xml" \
               -d '<?xml version="1.0"?><d:propfind xmlns:d="DAV:"><d:prop><d:displayname/></d:prop></d:propfind>' \
               "$WEBDAV_URL" \
               -v
               
      - name: Install rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash

      - name: Configure rclone for WebDAV
        env:
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASS: ${{ secrets.WEBDAV_PASS }}
        run: |
          mkdir -p $HOME/.config/rclone
          cat > $HOME/.config/rclone/rclone.conf <<EOF
          [webdav-backup]
          type = webdav
          url = $WEBDAV_URL
          vendor = other
          user = $WEBDAV_USER
          pass_plain = $WEBDAV_PASS
          EOF
          chmod 600 $HOME/.config/rclone/rclone.conf

      - name: Upload to WebDAV
        env:
          BACKUP_FILE: ${{ steps.encrypt.outputs.filename }}
        run: |
          echo "üì§ Uploading $BACKUP_FILE to WebDAV..."
          rclone copy "$BACKUP_FILE" webdav-backup:warden-worker/production/ \
            --create-empty-src-dirs \
            --progress \
            --retries 3 \
            --low-level-retries 5 \
            --transfers=1
          echo "‚úÖ Upload successful"

      - name: Cleanup old backups on WebDAV
        run: |
          echo "üßπ Cleaning backups older than ${{ env.BACKUP_RETENTION_DAYS }} days..."
          # rclone can delete by age directly
          rclone delete webdav-backup:warden-worker/production/ \
            --include "*.sql.gz" --include "*.sql.gz.enc" \
            --min-age ${{ env.BACKUP_RETENTION_DAYS }}d \
            --dry-run  # üëâ REMOVE THIS LINE AFTER TESTING

          # After verifying, replace `--dry-run` with:
          # rclone delete ... (no --dry-run)
          #
          # ‚ö†Ô∏è Caution: Test first! WebDAV delete is irreversible.

  # ‚Äî‚Äî dev job is identical, just change:
  #    D1_DATABASE_ID_DEV
  #    path: warden-worker/dev/
  #    filename prefix: vault1_dev_...
  # I'll omit it for brevity ‚Äî you can copy & adjust.
